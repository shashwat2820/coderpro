{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the implementation of the cnn classification model of the mnist dataset for handwritten digits  \r\n",
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "import tensorflow as tf \r\n",
    "# Import MNIST dataset under Keras API\r\n",
    "# MNIST - Modified National Institute of Standards and Technology\r\n",
    "# Splitting dataset into training & testing,\r\n",
    "# where x_train & x_test contains greyscale RGB codes from 0 - 255,\r\n",
    "# and y_train & y_test contains labels from 0 - 9 (actual numbers)\r\n",
    "(x_train , y_train) , (x_test , y_test ) = tf.keras.datasets.mnist.load_data()\r\n",
    "#MNIST consists of 60000 training examples and 10000 testing examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d586dee400>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualization and data loading confirmation\r\n",
    "import matplotlib.pyplot as plt  \r\n",
    "%matplotlib inline \r\n",
    "image_index = 7777 # can be any number between 0 to 60000 \r\n",
    "print(y_train[image_index])\r\n",
    "plt.imshow(x_train[image_index] , cmap = 'Greys')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# to show the shape of the loaded dataset\r\n",
    "print(x_train.shape)\r\n",
    "print(x_test.shape)\r\n",
    "print(y_train.shape)\r\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :  (60000, 28, 28, 1)\n",
      "the number of images in x_train:  60000\n",
      "the numeber of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# resashaping the pixel data arrays to have a single color channel i.e grey scale \r\n",
    "x_train = x_train.reshape(x_train.shape[0] , 28 , 28 , 1)\r\n",
    "x_test = x_test.reshape(x_test.shape[0] , 28 , 28 , 1)\r\n",
    "input_shape = (28 ,28 , 1 )\r\n",
    "\r\n",
    "# to make sure that the datatype of the pixel matrixs is float \r\n",
    "x_train = x_train.astype('float32')\r\n",
    "x_test = x_test.astype('float32')\r\n",
    "\r\n",
    "# normalizing(puting them in the range[0,1] ) the grey scale values of the pixel by dividing it by 255(maximmum grey scale value-- for white)\r\n",
    "x_train  /= 255  \r\n",
    "x_test /= 255\r\n",
    "print(\"x_train shape : \" ,   x_train.shape)\r\n",
    "print(\"the number of images in x_train: \", x_train.shape[0] )\r\n",
    "print(\"the numeber of images in x_test\"  ,  x_test.shape[0])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of the cnn model\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Conv2D , Dense , MaxPooling2D , Dropout , Flatten \r\n",
    "\r\n",
    "model = Sequential()# Keras API fro CNN\r\n",
    "\r\n",
    "model.add(Conv2D(28, kernel_size=(3,3) , input_shape = input_shape)) # Convlational Layer , performs the convolution \r\n",
    "#(no.of filters , filter/kernel size , input_shape(by default you have to include this argument if you are taking this layer as the first layer))\r\n",
    "\r\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))  # reduces the size of the input for the neural network\r\n",
    "# by taking the maximum element from the input matrix in according to the the pool_size = (2,2) by default)\r\n",
    "\r\n",
    "model.add(Flatten()) # flattens the input for the nn by converting it to a vector \r\n",
    "model.add(Dense(128 , activation = tf.nn.relu))  #  outputs 'activation(dot(input,kernel) + bias)' , kernel is the weight matrix created by the layer  Dense(no. of units , actvatiomn function)\r\n",
    "\r\n",
    "model.add(Dropout(0.2)) # the dropout layer randomly sets the input units to 0 ath the frequency of rate , here rate = 0.2 , it avoids the overfitting of the model \r\n",
    "\r\n",
    "model.add(Dense(10, activation = tf.nn.softmax))\r\n",
    "\r\n",
    "# the above will create a basic cnn model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 28s 14ms/step - loss: 0.2210 - accuracy: 0.9336\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0863 - accuracy: 0.9734\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0597 - accuracy: 0.9808\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0461 - accuracy: 0.9852\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0354 - accuracy: 0.9881\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0309 - accuracy: 0.9896\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0239 - accuracy: 0.9921\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0218 - accuracy: 0.9925\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0219 - accuracy: 0.9930\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0195 - accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d586e6bb20>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimizing the model \r\n",
    "model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])\r\n",
    "\r\n",
    "model.fit(x=x_train , y=y_train , epochs = 10)# fitting the model with 10 epochs/iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9853\n",
      "test loss : 0.0607902817428112\n",
      "test accuracy :  98.53000044822693 %\n"
     ]
    }
   ],
   "source": [
    "# model evaluation using x_test and y_test\r\n",
    "m = model.evaluate(x_test , y_test)\r\n",
    "print('test loss :' , m[0])\r\n",
    "print('test accuracy : ' , m[1]*100 ,'%')\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the recognised number is : 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOOElEQVR4nO3df+hUdb7H8dc7fxC4G+r1m3xpI71LBBHkbpNsGkuX5YpF+G0JQjPxQuASBX5BJNug7QdC3VrlGrXw3bL1XkxZciOj6NoVSYRYHMtb9uNmhbKK6Zh/bEax+9X3/eN7ar/qzGe+nXNmztj7+YBhZs57zpy3oy/PzPnMnI+5uwB8/11QdQMAuoOwA0EQdiAIwg4EQdiBIMZ3c2PTpk3zGTNmdHOTQCgHDhzQ8ePHrVmtUNjNbL6k/5A0TtIz7v5o6vEzZsxQvV4vskkACbVarWUt99t4Mxsn6SlJN0q6UtIiM7sy7/MB6Kwin9lnS/rY3T91979J2ixpoJy2AJStSNgvkfSXUfcPZcvOYGbLzKxuZvVGo1FgcwCK6PjReHcfcveau9f6+vo6vTkALRQJ+2FJl466/6NsGYAeVCTsuyVdbmYzzWyipIWStpbTFoCy5R56c/dhM7tH0n9rZOhtvbu/V1pnAEpVaJzd3V+V9GpJvQDoIL4uCwRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQXZ2yGZ1x6tSplrXh4eGObnvv3r3J+ssvv9yytnr16pK7OdPKlStb1vr7+5PrzpkzJ1m/5pprkvXx43svWuzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiCI3hsMxDn279+frN9///0tay+88EKhbbt7sm5muZ+7yLpj8cQTT3TsudesWZOsDw4OdmzbeRUKu5kdkPSFpFOSht29VkZTAMpXxp79X9z9eAnPA6CD+MwOBFE07C5pm5ntMbNlzR5gZsvMrG5m9UajUXBzAPIqGvbr3f2nkm6UdLeZ/fzsB7j7kLvX3L3W19dXcHMA8ioUdnc/nF0fk/SipNllNAWgfLnDbmaTzOyH39yWNE/SvrIaA1CuIkfjp0t6MRsrHS/peXd/rZSugjlx4kSyfvvttyfre/bsKbMdSJoyZUqyPjAw0KVOypM77O7+qaSrS+wFQAcx9AYEQdiBIAg7EARhB4Ig7EAQ/MS1B0ydOjVZX7duXbI+d+7cMts5b0yePDlZv+qqq3I/93PPPZesz5w5M/dzV4U9OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTh7D/jqq6+S9SeffLJLnZQvNdbd7vsBCxYsSNanTZuWrF977bXJejTs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZe8BHH32UrG/evLlLnZxr3LhxyfrGjRuT9ZtvvrllbdKkSbl6Qj7s2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZe8BTTz1VdQst7dy5M1mfM2dOlzpBUW337Ga23syOmdm+UcummtnrZrY/u05PZg2gcmN5G/8HSfPPWrZK0nZ3v1zS9uw+gB7WNuzuvlPSibMWD0jakN3eIOmWctsCULa8B+imu/uR7PZnkqa3eqCZLTOzupnVG41Gzs0BKKrw0Xh3d0meqA+5e83da319fUU3ByCnvGE/amb9kpRdHyuvJQCdkDfsWyUtzW4vlfRSOe0A6JS24+xmtknSDZKmmdkhSb+R9KikP5rZnZIOSrqtk01+391xxx3J+jPPPNOlTs41MDCQrF988cXJ+qJFi1rW5s8/e5DnTLVaLVnHd9M27O7e6m/rFyX3AqCD+LosEARhB4Ig7EAQhB0IgrADQdjIF+C6o1areb1e79r2zhdHjx5N1lesWJGsP//882W2c4Z2/z7MLPdzjx+fHgxqN6y3fPnyZH3evHkta1dffXVy3fNVrVZTvV5v+pfCnh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmCc/Txw+vTpZH3Tpk0ta3fddVdy3ZMnTybrnRxn77TUdNOrV69Orjs4OJisT5w4MU9LHcc4OwDCDkRB2IEgCDsQBGEHgiDsQBCEHQiCKZvPAxdckP4/efHixblqkvTJJ58k66+99lqyft999yXrqe8IfPnll8l1ixoeHm5Zu/fee5Prfv3118n6Aw88kKunKrFnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEg+D07Oio1Xv3KK68k13366aeT9R07duTqaSyuu+66ZP2NN95I1tudE79TCv2e3czWm9kxM9s3atmDZnbYzPZml5vKbBhA+cbyNv4PkuY3Wb7W3Wdll1fLbQtA2dqG3d13SjrRhV4AdFCRA3T3mNk72dv8Ka0eZGbLzKxuZvVGo1FgcwCKyBv230n6saRZko5I+m2rB7r7kLvX3L3W19eXc3MAisoVdnc/6u6n3P20pN9Lml1uWwDKlivsZtY/6u4vJe1r9VgAvaHtYKCZbZJ0g6RpZnZI0m8k3WBmsyS5pAOSftW5FnE+u/DCC1vWbr311uS68+c3GwT6h3Zj4fv25d8Hvfnmm8l6u3P596K2YXf3RU0WP9uBXgB0EF+XBYIg7EAQhB0IgrADQRB2IAhOJd0Djh8/nqy3O61xlbZv356sHzx4sGWt3emYJ0yYkKxPnjw5WS+i3Sm4q/oJaxHs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgiPNvsLBDTp06lay//fbbLWtr164ttO1t27Yl659//nmh5y+i3anGzZqetfhbl112WcvaokXNflD5D+vWrUvWd+3alawX0e7nte2m0e5F51/HAHIh7EAQhB0IgrADQRB2IAjCDgRB2IEgwoyztzv178MPP5ysP/LII2W2E0bq9+xXXHFFFzs500MPPZSsL1y4sEuddA97diAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IIsw4+5YtW5J1xtG/f1LfnVi1alVy3XHjxpXdTuXa7tnN7FIz22Fm75vZe2a2PFs+1cxeN7P92fWUzrcLIK+xvI0flrTC3a+U9DNJd5vZlZJWSdru7pdL2p7dB9Cj2obd3Y+4+1vZ7S8kfSDpEkkDkjZkD9sg6ZYO9QigBN/pAJ2ZzZD0E0l/ljTd3Y9kpc8kTW+xzjIzq5tZvdFoFOkVQAFjDruZ/UDSFkmD7v7X0TUfOSth0zMTuvuQu9fcvdbX11eoWQD5jSnsZjZBI0Hf6O5/yhYfNbP+rN4v6VhnWgRQhrZDbzZyruBnJX3g7mtGlbZKWirp0ez6pY50WJL+/v6qW0DJ2v1MNTW8dj5OuVzUWP7EcyUtkfSume3Nlv1aIyH/o5ndKemgpNs60iGAUrQNu7vvktRqJoBflNsOgE7h67JAEIQdCIKwA0EQdiAIwg4EEWawce7cucn6ypUrk/XHH3+8zHbCmDKl9Y8hBwcHk+suXrw4WU9NBy19P3+mWgR7diAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IIsw4+8jP8ltbvXp1sr5gwYKWtd27dyfXHRoaStY//PDDZL2THnvssWR9woQJyfpFF12UrC9ZsiT3c6Nc7NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAgbmcylO2q1mtfr9a5tD4imVqupXq83/VIJe3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCKJt2M3sUjPbYWbvm9l7ZrY8W/6gmR02s73Z5abOtwsgr7GcvGJY0gp3f8vMfihpj5m9ntXWuvsTnWsPQFnGMj/7EUlHsttfmNkHki7pdGMAyvWdPrOb2QxJP5H052zRPWb2jpmtN7Om8/yY2TIzq5tZvdFoFOsWQG5jDruZ/UDSFkmD7v5XSb+T9GNJszSy5/9ts/Xcfcjda+5e6+vrK94xgFzGFHYzm6CRoG909z9JkrsfdfdT7n5a0u8lze5cmwCKGsvReJP0rKQP3H3NqOX9ox72S0n7ym8PQFnGcjR+rqQlkt41s73Zsl9LWmRmsyS5pAOSftWB/gCUZCxH43dJavb72FfLbwdAp/ANOiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBBdnbLZzBqSDo5aNE3S8a418N30am+92pdEb3mV2dtl7t70/G9dDfs5Gzeru3utsgYSerW3Xu1Lore8utUbb+OBIAg7EETVYR+qePspvdpbr/Yl0VteXemt0s/sALqn6j07gC4h7EAQlYTdzOab2f+Z2cdmtqqKHloxswNm9m42DXW94l7Wm9kxM9s3atlUM3vdzPZn103n2Kuot56YxjsxzXilr13V0593/TO7mY2T9JGkf5V0SNJuSYvc/f2uNtKCmR2QVHP3yr+AYWY/l3RS0n+6+1XZsn+XdMLdH83+o5zi7vf2SG8PSjpZ9TTe2WxF/aOnGZd0i6R/U4WvXaKv29SF162KPftsSR+7+6fu/jdJmyUNVNBHz3P3nZJOnLV4QNKG7PYGjfxj6boWvfUEdz/i7m9lt7+Q9M0045W+dom+uqKKsF8i6S+j7h9Sb8337pK2mdkeM1tWdTNNTHf3I9ntzyRNr7KZJtpO491NZ00z3jOvXZ7pz4viAN25rnf3n0q6UdLd2dvVnuQjn8F6aex0TNN4d0uTaca/VeVrl3f686KqCPthSZeOuv+jbFlPcPfD2fUxSS+q96aiPvrNDLrZ9bGK+/lWL03j3WyacfXAa1fl9OdVhH23pMvNbKaZTZS0UNLWCvo4h5lNyg6cyMwmSZqn3puKequkpdntpZJeqrCXM/TKNN6tphlXxa9d5dOfu3vXL5Ju0sgR+U8k3V9FDy36+mdJ/5td3qu6N0mbNPK27u8aObZxp6R/krRd0n5J/yNpag/19l+S3pX0jkaC1V9Rb9dr5C36O5L2Zpebqn7tEn115XXj67JAEBygA4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEg/h/Mi0jjlgrvZwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction using our trained model\r\n",
    "image_index = 7777\r\n",
    "plt.imshow(x_test[image_index].reshape(28,28) , cmap='Greys')\r\n",
    "pred = model.predict(x_test[image_index].reshape(1,28,28,1))\r\n",
    "\r\n",
    "print(\"the recognised number is :\" , pred.argmax())\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c62bde2bd420ee1979732cd240f717f623403773863cbe09c44ab7a575b370b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}